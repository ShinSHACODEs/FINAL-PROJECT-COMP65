import requests
from datetime import datetime
import os
from selenium.webdriver.chrome.options import Options
import pandas as pd
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ปีเก่าสุดของ CT
def start_yearfor(data=None, default_year=2021):
    if data and "year" in data:
        return min(data["year"])
    else:
        return default_year

# ฟังก์ชั่นการทำงานของการดึงข้อมูล ของเว็บ ClimateWatch

def urlCW(source_id, gas_id, max_pages=200):
    base_URL = "https://www.climatewatchdata.org/api/v1/data/historical_emissions"
    all_data = []
    page = 1

    start_year = 2022
    end_year = datetime.now().year

    while True:
        params = {
            "source_ids[]": source_id,
            "gas_ids[]": gas_id,
            "page": page,
            "per_page": 10000,
            "start_year": start_year,
            "end_year": end_year,
            "sort_col": "country",
            "sort_dir": "ASC"
        }
        response = requests.get(base_URL, params=params)
        data = response.json()

        if not data.get("data"):
            break

        all_data.extend(data["data"])
        df = pd.DataFrame.from_dict(data["data"])

        if 'unit' in df.columns:
            df['unit'] = df['unit'].replace('MtCO₂e', 'MtCO2e')

        print(df)

        if page < max_pages:
            page += 1
        else:
            break

    final_df = pd.DataFrame.from_dict(all_data)

    try:
        existing_df = pd.read_csv("ClimateWatchDATA.csv")
        final_df = pd.concat([existing_df, final_df], ignore_index=True)
    except FileNotFoundError:
        pass

    final_df.to_csv("ClimateWatchDATA.csv", index=False)

source_id = [214, 215, 216, 217]
gas_id = [474, 475, 476, 477]
# urlCW(source_id, gas_id)

# ฟังก์ชั่นดึงข้อมูลจากเว็บ Our World in Data
def urlOWD():
    current_year = datetime.now().year
    years = list(range(start_yearfor(), current_year))

    urls = {
        "CO2": [
            "https://ourworldindata.org/grapher/cumulative-co-emissions.csv?v=1&csvType=full&useColumnShortNames=true",
            "https://ourworldindata.org/grapher/co-emissions-by-sector.csv?v=1&csvType=full&useColumnShortNames=true",
            "https://ourworldindata.org/grapher/co2-by-source.csv?v=1&csvType=full&useColumnShortNames=true",
        ],
        "CH4": [
            "https://ourworldindata.org/grapher/methane-emissions.csv?v=1&csvType=full&useColumnShortNames=true",
            "https://ourworldindata.org/grapher/methane-emissions-by-sector.csv?v=1&csvType=full&useColumnShortNames=true"
        ],
        "N2O": [
            "https://ourworldindata.org/grapher/nitrous-oxide-emissions.csv?v=1&csvType=full&useColumnShortNames=true",
            "https://ourworldindata.org/grapher/nitrous-oxide-emissions-by-sector.csv?v=1&csvType=full&useColumnShortNames=true"
        ]
    }

    dataframes = {}

    for gas, url_list in urls.items():
        dataframes[gas] = [pd.read_csv(url, storage_options={'User-Agent': 'Our World In Data data fetch/1.0'}) for url in url_list]

    for gas, df_list in dataframes.items():
        for i, df in enumerate(df_list):
            if 'Year' in df.columns:
                df = df[(df['Year'] >= start_yearfor()) & (df['Year'] <= current_year)]

            filename = f"{gas}_ourworld_{i+1}.csv"

            try:
                existing_df = pd.read_csv(filename)
                df = pd.concat([existing_df, df], ignore_index=True)
            except FileNotFoundError:
                pass

            df.to_csv(filename, index=False)
# urlOWD()

# รับเอาค่าที่มากที่สุดแต่ละปีีมา
def urlCT2():
    gases = ["co2e_100yr", "co2", "n2o", "ch4"]
    current_year = datetime.now().year
    years = list(range(current_year - 1, current_year + 1))

    results = []

    for gas in gases:
        for year in years:
            url = f"https://api.c10e.org/v6/app/emissions?years={year}&gas={gas}&subsectors=&excludeForestry=true"
            response = requests.get(url)
            json_data = response.json()

            if "totals" in json_data:
                total = json_data["totals"]
                results.append({
                    'Gas': gas,
                    'Year': year,
                    'Total Value': total['value']
                })
                print(f"Gas: {gas}, Year: {year}, Total Value: {total['value']}")

    df = pd.DataFrame(results)

    try:
        existing_df = pd.read_csv("ClimateTrace_Total.csv")
        df = pd.concat([existing_df, df], ignore_index=True)
    except FileNotFoundError:
        pass

    df.to_csv("ClimateTrace_Total.csv", index=False)
# urlCT2()

def urlCT3():
    current_year = datetime.now().year
    last_years_file = f"trace_data_combined_false_since_2015_to_{current_year - 1}.csv"
    
    # หากไฟล์ของปีที่แล้วมีอยู่ ลบไฟล์
    if os.path.exists(last_years_file):
        os.remove(last_years_file)
        print(f"ลบไฟล์ของปี {current_year - 1} แล้ว")

    # ตั้งค่าตัวเลือกสำหรับ WebDriver
    option = Options()
    option.add_experimental_option("detach", True)
    driver = webdriver.Chrome(options=option)
    
    # ไปที่ URL ที่จะดาวน์โหลดไฟล์
    driver.get(f"https://api.c10e.org/v6/country/emissions/timeseries/subsectors?since=2015&to={current_year}&download=csv&combined=false")
    
    # รอให้ดาวน์โหลดไฟล์
    time.sleep(5)
    
    # ปิด WebDriver
    driver.quit()
# urlCT3()

def urlCarMo(): 
    today_date = datetime.now().strftime('%Y-%m-%d')  # สร้างวันที่ในรูปแบบ YYYY-MM-DD
    download_file_name = f"carbonmonitor-global_datas_{today_date}.csv"  # ตั้งชื่อไฟล์ดาวน์โหลด

    # ลบไฟล์ที่ไม่ใช่วันปัจจุบัน
    for file in os.listdir():
        if file.startswith("carbonmonitor-global_datas_") and file.endswith(".csv"):
            # ตรวจสอบว่าไฟล์นั้นไม่ตรงกับวันที่ปัจจุบัน
            file_date = file.split('_')[-1].split('.')[0]  # ดึงวันที่จากชื่อไฟล์
            if file_date != today_date:  # ถ้าไม่ใช่วันที่ปัจจุบัน
                os.remove(file)
                print(f"ลบไฟล์เก่า: {file}")

    # ตั้งค่า Options ของ Chrome
    option = Options()
    option.add_experimental_option("detach", True)
    driver = webdriver.Chrome(options=option)

    # ไปที่ URL สำหรับดาวน์โหลดข้อมูล
    driver.get("https://datas.carbonmonitor.org/API/downloadFullDataset.php?source=carbon_global")
    time.sleep(5)  # รอให้ดาวน์โหลด

    # ปิด Chrome Driver
    driver.quit()
# urlCarMo()

#ต้องทำงานทุก 1ปี
def download_edgar(): 
    current_year = datetime.now().year
    last_year = current_year - 1
    download_file_name = f"EDGAR_{last_year}_GHG_booklet_{last_year}.xlsx"  # ตั้งชื่อไฟล์สำหรับ EDGAR

    # ลบไฟล์ปีเก่าก่อน
    old_file_name = f"EDGAR_{last_year}_GHG_booklet_{last_year}.xlsx"
    if os.path.exists(old_file_name):
        os.remove(old_file_name)
        print(f"ลบไฟล์ของปี {last_year} ออกแล้ว")

    options = Options()
    options.add_experimental_option("detach", True)
    service = Service()
    driver = webdriver.Chrome(service=service, options=options)

    # เปิดหน้าเว็บ EDGAR สำหรับปีที่แล้ว
    driver.get(f"https://edgar.jrc.ec.europa.eu/report_{last_year}#emissions_table")
    wait = WebDriverWait(driver, 20)

    # เลื่อนหน้าให้เห็นปุ่มดาวน์โหลด
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)

    # ค้นหาปุ่มดาวน์โหลด
    download_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//a[contains(@href, ".xlsx")]')))
    
    # คลิกปุ่มดาวน์โหลด
    driver.execute_script("arguments[0].click();", download_button)
    time.sleep(10)  # รอให้ดาวน์โหลดเสร็จ
    print(f"ดาวน์โหลดข้อมูลจาก EDGAR: {download_file_name}")
    
    driver.quit()
# download_edgar()
