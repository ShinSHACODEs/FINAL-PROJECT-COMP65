from helium import start_firefox
from bs4 import BeautifulSoup
import pandas as pd
import time
from datetime import datetime, timedelta
import os

def tmd():
    url = "https://www.tmd.go.th/climate/daily"
    browser = start_firefox(url, headless=True)
    time.sleep(5)

    soup = BeautifulSoup(browser.page_source, 'html.parser')
    browser.quit()

    tables = soup.find_all('table', class_='table')
    rows = []

    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

    for table in tables:
        for row in table.find_all('tr'):
            cells = row.find_all('td')
            row_data = [cell.get_text(strip=True) for cell in cells]
            if row_data and row_data[0] != '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...' and len(row_data) == 8:
                rows.append(row_data)

    columns = [
        "‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏≠‡∏∏‡∏ï‡∏∏‡∏ô‡∏¥‡∏¢‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤", "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î", "‡∏ó‡∏¥‡∏®",
        "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏Å‡∏°./‡∏ä‡∏°.)", "‡πÄ‡∏ß‡∏•‡∏≤", "‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ù‡∏ô ‡∏°‡∏°.", "‡∏£‡∏ß‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏õ‡∏µ"
    ]

    df_new = pd.DataFrame(rows, columns=columns)
    df_new["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"] = yesterday

    # üîç ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å artifact ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ fallback ‡πÑ‡∏õ default
    artifact_path = os.path.join("artifact_data", "TMDdata.csv")
    default_path = "TMDdata.csv"
    file_path = artifact_path if os.path.exists(artifact_path) else default_path

    if os.path.exists(file_path):
        try:
            df_existing = pd.read_csv(file_path, encoding="utf-8-sig")
        except Exception as e:
            print("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå:", e)
            df_existing = pd.DataFrame()
    else:
        df_existing = pd.DataFrame()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    is_duplicate = df_existing.merge(
        df_new[["‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏≠‡∏∏‡∏ï‡∏∏‡∏ô‡∏¥‡∏¢‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"]],
        on=["‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏≠‡∏∏‡∏ï‡∏∏‡∏ô‡∏¥‡∏¢‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"],
        how="inner"
    )

    if not is_duplicate.empty:
        print("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥")
        return

    # ‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
    df_combined = pd.concat([df_existing, df_new], ignore_index=True)
    df_combined.drop_duplicates(subset=["‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏≠‡∏∏‡∏ï‡∏∏‡∏ô‡∏¥‡∏¢‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"], keep="last", inplace=True)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡∏°‡πà
    df_combined.to_csv("TMDdata.csv", index=False, encoding="utf-8-sig")
    print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:", "TMDdata.csv")

if __name__ == "__main__":
    tmd()
